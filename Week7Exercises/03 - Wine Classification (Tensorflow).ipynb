{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Introduction #2\n",
    "\n",
    "This exercise is adapted from https://www.springboard.com/blog/beginners-guide-neural-network-in-python-scikit-learn-0-18/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have successfully used SciKit Learn's MLP to work on the built-in Breast Cancer Data Set, let's try another one!\n",
    "\n",
    "Download the wine dataset from UCI Machine learning repository (http://archive.ics.uci.edu/ml/datasets/Wine/). Import the dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_csv('./Data/Wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the dataframe - what are the first few rows of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Alcohol               178 non-null    float64\n",
      " 1   Malic_Acid            178 non-null    float64\n",
      " 2   Ash                   178 non-null    float64\n",
      " 3   Ash_Alcanity          178 non-null    float64\n",
      " 4   Magnesium             178 non-null    int64  \n",
      " 5   Total_Phenols         178 non-null    float64\n",
      " 6   Flavanoids            178 non-null    float64\n",
      " 7   Nonflavanoid_Phenols  178 non-null    float64\n",
      " 8   Proanthocyanins       178 non-null    float64\n",
      " 9   Color_Intensity       178 non-null    float64\n",
      " 10  Hue                   178 non-null    float64\n",
      " 11  OD280                 178 non-null    float64\n",
      " 12  Proline               178 non-null    int64  \n",
      " 13  Customer_Segment      178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "# find out the attributes in the dataset\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the total instances and number of features\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>178.0</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>11.03</td>\n",
       "      <td>12.3625</td>\n",
       "      <td>13.050</td>\n",
       "      <td>13.6775</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic_Acid</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>1.865</td>\n",
       "      <td>3.0825</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.5575</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>10.60</td>\n",
       "      <td>17.2000</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>178.0</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>70.00</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.7425</td>\n",
       "      <td>2.355</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>2.135</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_Intensity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>4.690</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>178.0</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>278.00</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>673.500</td>\n",
       "      <td>985.0000</td>\n",
       "      <td>1680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_Segment</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.938202</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count        mean         std     min       25%  \\\n",
       "Alcohol               178.0   13.000618    0.811827   11.03   12.3625   \n",
       "Malic_Acid            178.0    2.336348    1.117146    0.74    1.6025   \n",
       "Ash                   178.0    2.366517    0.274344    1.36    2.2100   \n",
       "Ash_Alcanity          178.0   19.494944    3.339564   10.60   17.2000   \n",
       "Magnesium             178.0   99.741573   14.282484   70.00   88.0000   \n",
       "Total_Phenols         178.0    2.295112    0.625851    0.98    1.7425   \n",
       "Flavanoids            178.0    2.029270    0.998859    0.34    1.2050   \n",
       "Nonflavanoid_Phenols  178.0    0.361854    0.124453    0.13    0.2700   \n",
       "Proanthocyanins       178.0    1.590899    0.572359    0.41    1.2500   \n",
       "Color_Intensity       178.0    5.058090    2.318286    1.28    3.2200   \n",
       "Hue                   178.0    0.957449    0.228572    0.48    0.7825   \n",
       "OD280                 178.0    2.611685    0.709990    1.27    1.9375   \n",
       "Proline               178.0  746.893258  314.907474  278.00  500.5000   \n",
       "Customer_Segment      178.0    1.938202    0.775035    1.00    1.0000   \n",
       "\n",
       "                          50%       75%      max  \n",
       "Alcohol                13.050   13.6775    14.83  \n",
       "Malic_Acid              1.865    3.0825     5.80  \n",
       "Ash                     2.360    2.5575     3.23  \n",
       "Ash_Alcanity           19.500   21.5000    30.00  \n",
       "Magnesium              98.000  107.0000   162.00  \n",
       "Total_Phenols           2.355    2.8000     3.88  \n",
       "Flavanoids              2.135    2.8750     5.08  \n",
       "Nonflavanoid_Phenols    0.340    0.4375     0.66  \n",
       "Proanthocyanins         1.555    1.9500     3.58  \n",
       "Color_Intensity         4.690    6.2000    13.00  \n",
       "Hue                     0.965    1.1200     1.71  \n",
       "OD280                   2.780    3.1700     4.00  \n",
       "Proline               673.500  985.0000  1680.00  \n",
       "Customer_Segment        2.000    3.0000     3.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use describe to find out more about the data\n",
    "dataframe.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1caab7ada90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe['Customer_Segment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 125 samples for training and 53 for validation\n"
     ]
    }
   ],
   "source": [
    "#val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "val_dataframe = dataframe.sample(frac=0.3, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. multiclass target requires 1 hot encoding\n",
    "# 2. multiclass requires a different activation function\n",
    "# 3. you might not need the dropoff layer\n",
    "# 4, you need a different loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"Customer_Segment\")\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(labels)\n",
    "    encoded_y = encoder.transform(labels)\n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    dummy_y = np_utils.to_categorical(encoded_y)    \n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), dummy_y))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'Alcohol': <tf.Tensor: shape=(), dtype=float64, numpy=13.72>, 'Malic_Acid': <tf.Tensor: shape=(), dtype=float64, numpy=1.43>, 'Ash': <tf.Tensor: shape=(), dtype=float64, numpy=2.5>, 'Ash_Alcanity': <tf.Tensor: shape=(), dtype=float64, numpy=16.7>, 'Magnesium': <tf.Tensor: shape=(), dtype=int64, numpy=108>, 'Total_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=3.4>, 'Flavanoids': <tf.Tensor: shape=(), dtype=float64, numpy=3.67>, 'Nonflavanoid_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=0.19>, 'Proanthocyanins': <tf.Tensor: shape=(), dtype=float64, numpy=2.04>, 'Color_Intensity': <tf.Tensor: shape=(), dtype=float64, numpy=6.8>, 'Hue': <tf.Tensor: shape=(), dtype=float64, numpy=0.89>, 'OD280': <tf.Tensor: shape=(), dtype=float64, numpy=2.87>, 'Proline': <tf.Tensor: shape=(), dtype=int64, numpy=1285>}\n",
      "Customer_Segment: tf.Tensor([1. 0. 0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Customer_Segment:\", y)\n",
    "    \n",
    "#train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Import the StandardScalar library\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "# # Fit only to the training data\n",
    "#scaler.fit(train_ds)\n",
    "# # Fit only to the training data\n",
    "\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'Alcohol': <tf.Tensor: shape=(), dtype=float64, numpy=14.16>, 'Malic_Acid': <tf.Tensor: shape=(), dtype=float64, numpy=2.51>, 'Ash': <tf.Tensor: shape=(), dtype=float64, numpy=2.48>, 'Ash_Alcanity': <tf.Tensor: shape=(), dtype=float64, numpy=20.0>, 'Magnesium': <tf.Tensor: shape=(), dtype=int64, numpy=91>, 'Total_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=1.68>, 'Flavanoids': <tf.Tensor: shape=(), dtype=float64, numpy=0.7>, 'Nonflavanoid_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=0.44>, 'Proanthocyanins': <tf.Tensor: shape=(), dtype=float64, numpy=1.24>, 'Color_Intensity': <tf.Tensor: shape=(), dtype=float64, numpy=9.7>, 'Hue': <tf.Tensor: shape=(), dtype=float64, numpy=0.62>, 'OD280': <tf.Tensor: shape=(), dtype=float64, numpy=1.71>, 'Proline': <tf.Tensor: shape=(), dtype=int64, numpy=660>}\n",
      "Customer_Segment: tf.Tensor([0. 0. 1.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Customer_Segment:\", y)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)\n",
    "#train_ds = train_ds.batch(18)\n",
    "#val_ds = val_ds.batch(18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers\n",
    "Magnesium = keras.Input(shape=(1,), name=\"Magnesium\", dtype=\"int64\")\n",
    "\n",
    "Proline = keras.Input(shape=(1,), name=\"Proline\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "#Proline = keras.Input(shape=(1,), name=\"Proline\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "Alcohol = keras.Input(shape=(1,), name=\"Alcohol\")\n",
    "Malic_Acid = keras.Input(shape=(1,), name=\"Malic_Acid\")\n",
    "Ash = keras.Input(shape=(1,), name=\"Ash\")\n",
    "Ash_Alcanity = keras.Input(shape=(1,), name=\"Ash_Alcanity\")\n",
    "Total_Phenols = keras.Input(shape=(1,), name=\"Total_Phenols\")\n",
    "Flavanoids = keras.Input(shape=(1,), name=\"Flavanoids\")\n",
    "Nonflavanoid_Phenols = keras.Input(shape=(1,), name=\"Nonflavanoid_Phenols\")\n",
    "Proanthocyanins = keras.Input(shape=(1,), name=\"Proanthocyanins\")\n",
    "Color_Intensity = keras.Input(shape=(1,), name=\"Color_Intensity\")\n",
    "Hue = keras.Input(shape=(1,), name=\"Hue\")\n",
    "OD280 = keras.Input(shape=(1,), name=\"OD280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = [\n",
    "    Magnesium,\n",
    "    Proline,\n",
    "    Alcohol,\n",
    "    Malic_Acid,\n",
    "    Ash,\n",
    "    Ash_Alcanity,\n",
    "    Total_Phenols,\n",
    "    Flavanoids,\n",
    "    Nonflavanoid_Phenols,\n",
    "    Proanthocyanins,\n",
    "    Color_Intensity,\n",
    "    Hue,\n",
    "    OD280,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Integer categorical features\n",
    "Magnesium_encoded = encode_categorical_feature(Magnesium, \"Magnesium\", train_ds, False)\n",
    "\n",
    "Proline_encoded = encode_categorical_feature(Proline, \"Proline\", train_ds, False)\n",
    "# String categorical features\n",
    "#Proline_encoded = encode_categorical_feature(Proline, \"Proline\", train_ds, True)\n",
    "\n",
    "# Numerical features\n",
    "Alcohol_encoded = encode_numerical_feature(Alcohol, \"Alcohol\", train_ds)\n",
    "Malic_Acid_encoded = encode_numerical_feature(Malic_Acid, \"Malic_Acid\", train_ds)\n",
    "Ash_encoded = encode_numerical_feature(Ash, \"Ash\", train_ds)\n",
    "Ash_Alcanity_encoded = encode_numerical_feature(Ash_Alcanity, \"Ash_Alcanity\", train_ds)\n",
    "Total_Phenols_encoded = encode_numerical_feature(Total_Phenols, \"Total_Phenols\", train_ds)\n",
    "Flavanoids_encoded = encode_numerical_feature(Flavanoids, \"Flavanoids\", train_ds)\n",
    "Nonflavanoid_Phenols_encoded = encode_numerical_feature(Nonflavanoid_Phenols, \"Nonflavanoid_Phenols\", train_ds)\n",
    "Proanthocyanins_encoded = encode_numerical_feature(Proanthocyanins, \"Proanthocyanins\", train_ds)\n",
    "Color_Intensity_encoded = encode_numerical_feature(Color_Intensity, \"Color_Intensity\", train_ds)\n",
    "Hue_encoded = encode_numerical_feature(Hue, \"Hue\", train_ds)\n",
    "OD280_encoded = encode_numerical_feature(OD280, \"OD280\", train_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        Magnesium_encoded,\n",
    "        Proline_encoded,\n",
    "        Alcohol_encoded,\n",
    "        Malic_Acid_encoded,\n",
    "        Ash_encoded,\n",
    "        Ash_Alcanity_encoded,\n",
    "        Total_Phenols_encoded,\n",
    "        Flavanoids_encoded,\n",
    "        Nonflavanoid_Phenols_encoded,\n",
    "        Proanthocyanins_encoded,\n",
    "        Color_Intensity_encoded,\n",
    "        Hue_encoded,\n",
    "        OD280_encoded,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "## change from 1 to 3 will fix shape. \n",
    "output = layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "#model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# tf.keras.metrics.categorical_crossentropy(\n",
    "#     y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 67ms/step - loss: 1.0400 - accuracy: 0.4880 - val_loss: 1.0651 - val_accuracy: 0.4528\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0158 - accuracy: 0.4640 - val_loss: 1.0225 - val_accuracy: 0.5094\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9800 - accuracy: 0.5280 - val_loss: 0.9817 - val_accuracy: 0.5472\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9306 - accuracy: 0.6160 - val_loss: 0.9433 - val_accuracy: 0.6226\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8804 - accuracy: 0.6560 - val_loss: 0.9075 - val_accuracy: 0.7170\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8725 - accuracy: 0.6800 - val_loss: 0.8744 - val_accuracy: 0.7547\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8329 - accuracy: 0.7680 - val_loss: 0.8427 - val_accuracy: 0.8302\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7787 - accuracy: 0.7520 - val_loss: 0.8118 - val_accuracy: 0.8491\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6993 - accuracy: 0.8160 - val_loss: 0.7818 - val_accuracy: 0.8679\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7356 - accuracy: 0.8000 - val_loss: 0.7531 - val_accuracy: 0.8868\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6554 - accuracy: 0.8720 - val_loss: 0.7248 - val_accuracy: 0.8868\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6451 - accuracy: 0.8080 - val_loss: 0.6979 - val_accuracy: 0.8868\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6152 - accuracy: 0.8800 - val_loss: 0.6718 - val_accuracy: 0.9245\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5761 - accuracy: 0.8800 - val_loss: 0.6471 - val_accuracy: 0.9245\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5508 - accuracy: 0.8880 - val_loss: 0.6232 - val_accuracy: 0.9245\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8720 - val_loss: 0.6004 - val_accuracy: 0.9434\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5239 - accuracy: 0.8880 - val_loss: 0.5783 - val_accuracy: 0.9245\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.9120 - val_loss: 0.5568 - val_accuracy: 0.9245\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.9200 - val_loss: 0.5362 - val_accuracy: 0.9245\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4677 - accuracy: 0.9280 - val_loss: 0.5157 - val_accuracy: 0.9245\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.8960 - val_loss: 0.4965 - val_accuracy: 0.9245\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.9360 - val_loss: 0.4783 - val_accuracy: 0.9245\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4044 - accuracy: 0.9040 - val_loss: 0.4607 - val_accuracy: 0.9245\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3630 - accuracy: 0.9200 - val_loss: 0.4439 - val_accuracy: 0.9245\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3648 - accuracy: 0.9200 - val_loss: 0.4283 - val_accuracy: 0.9245\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3138 - accuracy: 0.9840 - val_loss: 0.4135 - val_accuracy: 0.9245\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2952 - accuracy: 0.9440 - val_loss: 0.3991 - val_accuracy: 0.9245\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3064 - accuracy: 0.9360 - val_loss: 0.3856 - val_accuracy: 0.9245\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2975 - accuracy: 0.9280 - val_loss: 0.3728 - val_accuracy: 0.9434\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2685 - accuracy: 0.9520 - val_loss: 0.3609 - val_accuracy: 0.9434\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2638 - accuracy: 0.9600 - val_loss: 0.3495 - val_accuracy: 0.9434\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2826 - accuracy: 0.9520 - val_loss: 0.3391 - val_accuracy: 0.9434\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2397 - accuracy: 0.9440 - val_loss: 0.3294 - val_accuracy: 0.9434\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1975 - accuracy: 0.9840 - val_loss: 0.3201 - val_accuracy: 0.9434\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2418 - accuracy: 0.9360 - val_loss: 0.3113 - val_accuracy: 0.9434\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2251 - accuracy: 0.9680 - val_loss: 0.3026 - val_accuracy: 0.9434\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2321 - accuracy: 0.9600 - val_loss: 0.2945 - val_accuracy: 0.9434\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2260 - accuracy: 0.9680 - val_loss: 0.2870 - val_accuracy: 0.9434\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2165 - accuracy: 0.9600 - val_loss: 0.2800 - val_accuracy: 0.9434\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2169 - accuracy: 0.9520 - val_loss: 0.2730 - val_accuracy: 0.9434\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1729 - accuracy: 0.9760 - val_loss: 0.2666 - val_accuracy: 0.9434\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2272 - accuracy: 0.9360 - val_loss: 0.2604 - val_accuracy: 0.9434\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1962 - accuracy: 0.9600 - val_loss: 0.2544 - val_accuracy: 0.9434\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.9600 - val_loss: 0.2488 - val_accuracy: 0.9434\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1953 - accuracy: 0.9600 - val_loss: 0.2434 - val_accuracy: 0.9434\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1926 - accuracy: 0.9600 - val_loss: 0.2383 - val_accuracy: 0.9434\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1831 - accuracy: 0.9600 - val_loss: 0.2335 - val_accuracy: 0.9434\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1827 - accuracy: 0.9520 - val_loss: 0.2289 - val_accuracy: 0.9434\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1261 - accuracy: 0.9920 - val_loss: 0.2245 - val_accuracy: 0.9434\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1633 - accuracy: 0.9840 - val_loss: 0.2200 - val_accuracy: 0.9434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cac0fec190>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
